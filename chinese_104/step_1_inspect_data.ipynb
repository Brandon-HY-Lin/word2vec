{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Data of Employment Website 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1003\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1003\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1003\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1003' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1003\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1003\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1003' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import jieba\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, save\n",
    "from bokeh.models import HoverTool, value, LabelSet, Legend, ColumnDataSource\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dataset = './datasets/jobs_104.json'\n",
    "\n",
    "dataset_df = pd.read_json(filename_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>benefit</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "      <th>requirement</th>\n",
       "      <th>requirement_others</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>台北市內湖...</td>\n",
       "      <td>福利健全  ■ 優渥的薪資、獎金  ◎ 端午節、中秋節、年終獎金。  ◎ 定期依工作績效調...</td>\n",
       "      <td>芯鼎科技股份有限公司</td>\n",
       "      <td>不拘</td>\n",
       "      <td>- Driver development and fine tune of customiz...</td>\n",
       "      <td>- A BS degree in Computer Engineering, Electri...</td>\n",
       "      <td>待遇面議                                          ...</td>\n",
       "      <td>系統應用工程師-台北(CD2320)   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>台北市大安...</td>\n",
       "      <td>＊獎金福利＊1. 年節禮金2. 生日禮金3. 年終分紅4. 人才介紹獎金＊休假福利＊1. ...</td>\n",
       "      <td>銓鴻資訊有限公司</td>\n",
       "      <td>1年以上</td>\n",
       "      <td>1. 研究市場數據和交易數據，並進行交易策略研發。  2. 開發模型和工具，監控分析交易程序...</td>\n",
       "      <td>將先以電子履歷篩選增加效率，請注意以下事項： ■ 履歷請詳述相關經驗並請提供 Github/...</td>\n",
       "      <td>年薪 1,000,000~2,500,000元                       ...</td>\n",
       "      <td>計量交易員 Quantitative Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>新北市新店...</td>\n",
       "      <td>《薪酬福利＠HTC》我們極力落實利潤與員工分享的精神，透過多元的薪酬組合與完善的福利方案，...</td>\n",
       "      <td>宏達電 HTC Corporation_宏達國際電子股份有限公司</td>\n",
       "      <td>不拘</td>\n",
       "      <td>Join the creative thinkers at HTC Healthcare. ...</td>\n",
       "      <td>Requirement:-MS or PhD in computer science or ...</td>\n",
       "      <td>待遇面議                                          ...</td>\n",
       "      <td>(RD S/W) DeepQ - Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>桃園市中壢...</td>\n",
       "      <td>正職/全職人員之福利與訓練制度：  【薪酬福利】 -每年依市場薪資水準評估薪資調整專案 -...</td>\n",
       "      <td>OK超商_來來超商股份有限公司</td>\n",
       "      <td>不拘</td>\n",
       "      <td>OK超商認為，用心經營的企業，首重人才培訓。  因此，我們投入了大量的訓練資源，積極培育新一...</td>\n",
       "      <td>1.具服務熱忱，科系、經驗不拘，須輪班。 2.須自備交通工具及電腦網路設備(透過e-Lear...</td>\n",
       "      <td>月薪 31,000~33,000元                             ...</td>\n",
       "      <td>儲備幹部(大桃園地區)          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>新竹縣竹北...</td>\n",
       "      <td>【工作福利】彈性上下班。  【休假福利】週休二日、國定假日、婚假、產假、陪產假、特休假、彈...</td>\n",
       "      <td>神亞科技股份有限公司</td>\n",
       "      <td>3年以上</td>\n",
       "      <td>影像相關之深度學習演算法研究與開發</td>\n",
       "      <td>1. 有開發image processing相關應用經驗 2. 熟悉深度學習相關算法（e.g...</td>\n",
       "      <td>待遇面議                                          ...</td>\n",
       "      <td>AI 工程師               ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address  \\\n",
       "0                                           台北市內湖...   \n",
       "1                                           台北市大安...   \n",
       "2                                           新北市新店...   \n",
       "3                                           桃園市中壢...   \n",
       "4                                           新竹縣竹北...   \n",
       "\n",
       "                                             benefit  \\\n",
       "0   福利健全  ■ 優渥的薪資、獎金  ◎ 端午節、中秋節、年終獎金。  ◎ 定期依工作績效調...   \n",
       "1   ＊獎金福利＊1. 年節禮金2. 生日禮金3. 年終分紅4. 人才介紹獎金＊休假福利＊1. ...   \n",
       "2   《薪酬福利＠HTC》我們極力落實利潤與員工分享的精神，透過多元的薪酬組合與完善的福利方案，...   \n",
       "3   正職/全職人員之福利與訓練制度：  【薪酬福利】 -每年依市場薪資水準評估薪資調整專案 -...   \n",
       "4   【工作福利】彈性上下班。  【休假福利】週休二日、國定假日、婚假、產假、陪產假、特休假、彈...   \n",
       "\n",
       "                            company experience  \\\n",
       "0                        芯鼎科技股份有限公司         不拘   \n",
       "1                          銓鴻資訊有限公司       1年以上   \n",
       "2  宏達電 HTC Corporation_宏達國際電子股份有限公司         不拘   \n",
       "3                   OK超商_來來超商股份有限公司         不拘   \n",
       "4                        神亞科技股份有限公司       3年以上   \n",
       "\n",
       "                                         requirement  \\\n",
       "0  - Driver development and fine tune of customiz...   \n",
       "1  1. 研究市場數據和交易數據，並進行交易策略研發。  2. 開發模型和工具，監控分析交易程序...   \n",
       "2  Join the creative thinkers at HTC Healthcare. ...   \n",
       "3  OK超商認為，用心經營的企業，首重人才培訓。  因此，我們投入了大量的訓練資源，積極培育新一...   \n",
       "4                                  影像相關之深度學習演算法研究與開發   \n",
       "\n",
       "                                  requirement_others  \\\n",
       "0  - A BS degree in Computer Engineering, Electri...   \n",
       "1  將先以電子履歷篩選增加效率，請注意以下事項： ■ 履歷請詳述相關經驗並請提供 Github/...   \n",
       "2  Requirement:-MS or PhD in computer science or ...   \n",
       "3  1.具服務熱忱，科系、經驗不拘，須輪班。 2.須自備交通工具及電腦網路設備(透過e-Lear...   \n",
       "4  1. 有開發image processing相關應用經驗 2. 熟悉深度學習相關算法（e.g...   \n",
       "\n",
       "                                              salary  \\\n",
       "0  待遇面議                                          ...   \n",
       "1  年薪 1,000,000~2,500,000元                       ...   \n",
       "2  待遇面議                                          ...   \n",
       "3  月薪 31,000~33,000元                             ...   \n",
       "4  待遇面議                                          ...   \n",
       "\n",
       "                                               title  \n",
       "0                           系統應用工程師-台北(CD2320)   ...  \n",
       "1                           計量交易員 Quantitative Tr...  \n",
       "2                           (RD S/W) DeepQ - Comp...  \n",
       "3                           儲備幹部(大桃園地區)          ...  \n",
       "4                           AI 工程師               ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    - Driver development and fine tune of customiz...\n",
       "1    1. 研究市場數據和交易數據，並進行交易策略研發。  2. 開發模型和工具，監控分析交易程序...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements = dataset_df['requirement'] + ' ' + dataset_df['requirement_others']\n",
    "requirements[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Driver development and fine tune of customized HW accelerator for OpenCV/OpenCL/OpenVX/CNN.- iCatchOS(RTOS) vision process framework development and maintain (SDK/BSP)- Integration and maintain of in-house design algorithms and performance fine tune.- Discuss/Design & co-work with customers for vision related requests. - A BS degree in Computer Engineering, Electrical Engineering, or Computer Science- At least 1-3 years of embedded software development experience (Senior – more than 5 years) - Familiar with C/C++ programming language, nice to have experience in Assembly language- Knowledge of Real-Time concepts and have RTOS experience (ThreadX , FreeRTOS, eCos, RTLinux, …)- Good understanding of CPU (e.g. ARM, MIPS ..)  architecture- Image processing & analysis algorithm, Machine Learning, Deep Learning framework development experience, e.g. CNN, OpenCL, OpenVX, OpenCV, OpenGL- Self-motivated, good attitude, skilled in meeting deadlines and work collaboratively in a team environment- Ability to work under pressure and tight time frames- Ability to solve technical issues with strong communication skills , may involve customer interactions'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 研究市場數據和交易數據，並進行交易策略研發。  2. 開發模型和工具，監控分析交易程序運行情況研究，實施統計套利策略，並研發統計套利回測工具。  3. 熟悉python R 或者c++,有自主研發量化策略的能力。 4. 具備機率、統計、機器學習和金融市場研究經驗 。  求才若渴 如果你(妳)有下列特質：  是個懶人： 希望以最小的力氣達成目標，甚至提升品質，懂得善用工具增加生產力，重構提煉自有的程式庫。  有團隊精神： 懂得協同合作提升整體效益，將團隊目標置於個人之前。  充滿好奇心： 喜歡接觸、學習新事物，發現各種創新的可能。  熱愛程式： 充滿熱情想改變世界，將巧思及創造力注入每一行程式碼。   歡迎加入我們！ 一起邁向偉大航道 : ) 將先以電子履歷篩選增加效率，請注意以下事項： ■ 履歷請詳述相關經驗並請提供 Github/Sample Code/作品，加速審核 。 ■ 我們非常重視求職者的職務申請，履歷將由相關團隊主管嚴謹評估，因履歷眾多，意者我們將主動聯繫，請求職者悉知並耐心等候。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "- Add custom Chinese phrases\n",
    "    - Reference: https://github.com/fxsjy/jieba\n",
    "- Tokenize Chinese/English\n",
    "    - For English: Normalize, Lemmatize, Remove English Stopwords\n",
    "    - For Chinese: Remove Chinese Stopwords,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "    return jieba.cut(doc, cut_all=False)\n",
    "\n",
    "def set_chinese_custom_dictionary():\n",
    "    filename_userdict = './dictionary/custom_dictionary.txt'\n",
    "    jieba.load_userdict(filename_userdict)\n",
    "\n",
    "\n",
    "def get_chinese_stopwords():\n",
    "    \"\"\"\n",
    "    Get Chinese stopwords\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = './dictionary/中文停用词表.txt'\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        stopwords = [w.strip() for w in lines]\n",
    "        \n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def preprocess(raw_docs):\n",
    "    \"\"\"\n",
    "    Normalize, tokenize, remove stopwords, use custom dictionary\n",
    "    \n",
    "    Args:\n",
    "        raw_docs (list(str)):\n",
    "        \n",
    "    Returns:\n",
    "        docs (list(list(str))): list of tokens in a document\n",
    "    \"\"\"\n",
    "    \n",
    "    docs = []\n",
    "    \n",
    "    # Declare lemmatizer\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # define customized stopwords\n",
    "    stopwords_custom = ['•', '與', '★', '●', '（', '’', '－', '✦', '◆', '◼', '✪', \n",
    "                        '※', '⁺', '', '', '·', '‧', '・', '）', '○', '】', '【', '✓', '']\n",
    "    \n",
    "    stopwords_chinese = get_chinese_stopwords()\n",
    "    \n",
    "    set_chinese_custom_dictionary()\n",
    "    \n",
    "    for d in tqdm(raw_docs):\n",
    "        \n",
    "        d = d.lower()\n",
    "        \n",
    "        tokens = []\n",
    "        \n",
    "        for t in tokenizer(d):\n",
    "            # Strip English Punctuation\n",
    "            t = gensim.parsing.preprocessing.strip_punctuation(t)\n",
    "            \n",
    "            # Remove numeric\n",
    "            t = gensim.parsing.preprocessing.strip_numeric(t)\n",
    "            \n",
    "            t = t.strip()\n",
    "            \n",
    "            if t is '':\n",
    "                continue\n",
    "                \n",
    "            if t not in stopwords_custom:\n",
    "                if t not in stopwords_chinese:\n",
    "                    if t not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "                        # Only Lemmatize the plura because most Chinese user don't use past tense in job description.\n",
    "                        t = lemmatizer.lemmatize(t, pos='n')\n",
    "                        tokens.append(t)\n",
    "                        \n",
    "        docs.append(tokens)\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:07<00:00, 137.75it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = preprocess(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['driver', 'development', 'fine', 'tune', 'customized', 'hw', 'accelerator', 'opencv', 'opencl', 'openvx', 'cnn', 'icatchos', 'rtos', 'vision', 'process', 'framework', 'development', 'maintain', 'sdk', 'bsp', 'integration', 'maintain', 'house', 'design', 'algorithm', 'performance', 'fine', 'tune', 'discus', 'design', 'work', 'customer', 'vision', 'related', 'request', 'b', 'degree', 'engineering', 'electrical', 'engineering', 'science', 'year', 'embedded', 'software', 'development', 'experience', 'senior', '–', 'year', 'familiar', 'c', 'c', 'programming', 'language', 'nice', 'experience', 'assembly', 'language', 'knowledge', 'real', 'time', 'concept', 'rtos', 'experience', 'threadx', 'freertos', 'ecos', 'rtlinux', '…', 'good', 'understanding', 'cpu', 'e', 'g', 'arm', 'mips', 'architecture', 'image', 'processing', 'analysis', 'algorithm', 'machine', 'learning', 'deep', 'learning', 'framework', 'development', 'experience', 'e', 'g', 'cnn', 'opencl', 'openvx', 'opencv', 'opengl', 'self', 'motivated', 'good', 'attitude', 'skilled']\n"
     ]
    }
   ],
   "source": [
    "print(docs[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['研究', '市場', '數據', '交易', '數據', '並進行', '交易', '策略', '研發', '開發', '模型', '工具', '監控', '分析', '交易', '程序', '運行', '情況', '研究', '實施', '統計', '套利', '策略', '並', '研發', '統計', '套利', '回測', '工具', '熟悉', 'python', 'r', 'c', '自主', '研發', '量化', '策略', '能力', '具備', '機率', '統計', '機器學習', '金融', '市場', '研究', '經驗', '求才若渴', '妳', '下列', '特質', '個', '懶人', '希望', '最小', '力氣', '達成', '目標', '提升', '品質', '懂得', '善用', '工具', '增加', '生產力', '重構', '提煉', '自有', '程式', '庫', '有團隊', '精神', '懂得', '協同', '合作', '提升', '整體', '效益', '將團隊', '目標', '置於', '個', '之前', '充滿', '好奇心', '喜歡', '接觸', '學習', '新事物', '發現', '各種', '創新', '可能', '熱愛', '程式', '充滿', '熱情', '想', '改變', '世界', '將', '巧思', '創造力', '注入', '一行', '程式', '碼', '歡迎', '加入', '我們', '一起', '邁向偉大', '航道', '將先以', '電子', '履歷', '篩選', '增加', '效率', '請', '注意']\n"
     ]
    }
   ],
   "source": [
    "print(docs[1][:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_feature = 150\n",
    "window = 10\n",
    "min_count = 2\n",
    "# ingnore words with total frequency lower than this value.\n",
    "\n",
    "model = gensim.models.Word2Vec(size=size_feature,\n",
    "                              window=window,\n",
    "                              min_count=min_count,\n",
    "                              sg=1, # 1:Skip-Gram. 0:BOW\n",
    "                              workers=2)\n",
    "\n",
    "model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab: 6508\n",
      "\n",
      "The first 100 words:\n",
      "['driver', 'development', 'fine', 'tune', 'customized', 'hw', 'accelerator', 'opencv', 'opencl', 'openvx', 'cnn', 'rtos', 'vision', 'process', 'framework', 'maintain', 'sdk', 'bsp', 'integration', 'house', 'design', 'algorithm', 'performance', 'discus', 'work', 'customer', 'related', 'request', 'b', 'degree', 'engineering', 'electrical', 'science', 'year', 'embedded', 'software', 'experience', 'senior', '–', 'familiar', 'c', 'programming', 'language', 'nice', 'assembly', 'knowledge', 'real', 'time', 'concept', 'freertos', '…', 'good', 'understanding', 'cpu', 'e', 'g', 'arm', 'architecture', 'image', 'processing', 'analysis', 'machine', 'learning', 'deep', 'opengl', 'self', 'motivated', 'attitude', 'skilled', 'meeting', 'deadline', 'collaboratively', 'team', 'environment', 'ability', 'pressure', 'tight', 'frame', 'solve', 'technical', 'issue', 'strong', 'communication', 'skill', 'involve', 'interaction', '研究', '市場', '數據', '交易', '並進行', '策略', '研發', '開發', '模型', '工具', '監控', '分析', '程序', '運行']\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocab: {}'.format(len(model.wv.vocab)))\n",
    "print()\n",
    "print('The first 100 words:\\n{}'.format(list(model.wv.vocab.keys())[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 s, sys: 11.7 ms, total: 50.4 s\n",
      "Wall time: 26 s\n",
      "(3421946, 3729720)\n"
     ]
    }
   ],
   "source": [
    "%time results = model.train(sentences=docs, \\\n",
    "                     total_examples=len(docs), \\\n",
    "                     epochs=30, \\\n",
    "                     report_delay=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_model = './models/website_104.word2vec'\n",
    "\n",
    "model.save(filename_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load(filename_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning, deep, scene, bioinformatics, mining, cmm, 或開, intellengent, minimal, vision, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('learning', 0.6342628002166748),\n",
       " ('deep', 0.4663415551185608),\n",
       " ('scene', 0.40456992387771606),\n",
       " ('bioinformatics', 0.39270511269569397),\n",
       " ('mining', 0.38950565457344055),\n",
       " ('cmm', 0.3879614472389221),\n",
       " ('或開', 0.3879144787788391),\n",
       " ('intellengent', 0.3867086172103882),\n",
       " ('minimal', 0.385672003030777),\n",
       " ('vision', 0.38516154885292053)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'machine'\n",
    "results = model.wv.most_similar(word)\n",
    "\n",
    "words = []\n",
    "for w, prob in results:\n",
    "    print(w, end=', ')\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine, deep, onnx, supervised, reinforcement, original, unsupervised, dnn, tx, —, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('machine', 0.6342628002166748),\n",
       " ('deep', 0.6074545383453369),\n",
       " ('onnx', 0.4455774128437042),\n",
       " ('supervised', 0.4227384924888611),\n",
       " ('reinforcement', 0.41758525371551514),\n",
       " ('original', 0.4151538610458374),\n",
       " ('unsupervised', 0.41345110535621643),\n",
       " ('dnn', 0.41133540868759155),\n",
       " ('tx', 0.4099203050136566),\n",
       " ('—', 0.409529447555542)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'learning'\n",
    "results = model.wv.most_similar(word)\n",
    "\n",
    "words = []\n",
    "for w, prob in results:\n",
    "    print(w, end=', ')\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn, lstm, rcnn, resnet, bnn, 實作練習, gan, twn, vggnet, yolo, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rnn', 0.8737841248512268),\n",
       " ('lstm', 0.6624916195869446),\n",
       " ('rcnn', 0.6513897180557251),\n",
       " ('resnet', 0.6389967799186707),\n",
       " ('bnn', 0.6236380338668823),\n",
       " ('實作練習', 0.6181016564369202),\n",
       " ('gan', 0.6104133725166321),\n",
       " ('twn', 0.608122706413269),\n",
       " ('vggnet', 0.6025672554969788),\n",
       " ('yolo', 0.5942688584327698)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'cnn'\n",
    "results = model.wv.most_similar(word)\n",
    "\n",
    "words = []\n",
    "for w, prob in results:\n",
    "    print(w, end=', ')\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn, random, forest, multivariable, calculus, boosting, 回歸, natworks, sklearn, 聚類, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('knn', 0.729316234588623),\n",
       " ('random', 0.7163858413696289),\n",
       " ('forest', 0.7103894948959351),\n",
       " ('multivariable', 0.6472737789154053),\n",
       " ('calculus', 0.6351724863052368),\n",
       " ('boosting', 0.6249902248382568),\n",
       " ('回歸', 0.6242859959602356),\n",
       " ('natworks', 0.6240625977516174),\n",
       " ('sklearn', 0.6063175797462463),\n",
       " ('聚類', 0.6061213612556458)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'svm'\n",
    "results = model.wv.most_similar(word)\n",
    "\n",
    "words = []\n",
    "for w, prob in results:\n",
    "    print(w, end=', ')\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursive, 計學習, 如統, 推理, 貝葉斯, 神經, 常用, bnn, 熱誠與, 並應用, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recursive', 0.7047215104103088),\n",
       " ('計學習', 0.7027356028556824),\n",
       " ('如統', 0.7012736201286316),\n",
       " ('推理', 0.6592531204223633),\n",
       " ('貝葉斯', 0.6202261447906494),\n",
       " ('神經', 0.6144611239433289),\n",
       " ('常用', 0.6061349511146545),\n",
       " ('bnn', 0.5997304320335388),\n",
       " ('熱誠與', 0.5984153151512146),\n",
       " ('並應用', 0.5829022526741028)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = '深度'\n",
    "results = model.wv.most_similar(word)\n",
    "\n",
    "words = []\n",
    "for w, prob in results:\n",
    "    print(w, end=', ')\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Similar Words using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learning', 'deep', 'scene', 'bioinformatics', 'mining', 'cmm', '或開', 'intellengent', 'minimal', 'vision', 'learning', 'machine', 'deep', 'onnx', 'supervised', 'reinforcement', 'original', 'unsupervised', 'dnn', 'tx', '—', 'cnn', 'rnn', 'lstm', 'rcnn', 'resnet', 'bnn', '實作練習', 'gan', 'twn', 'vggnet', 'yolo', 'svm', 'knn', 'random', 'forest', 'multivariable', 'calculus', 'boosting', '回歸', 'natworks', 'sklearn', '聚類', '深度', 'recursive', '計學習', '如統', '推理', '貝葉斯', '神經', '常用', 'bnn', '熱誠與', '並應用']\n"
     ]
    }
   ],
   "source": [
    "similar_words = []\n",
    "key_words = ['machine', 'learning', 'cnn', 'svm', '深度']\n",
    "\n",
    "for key_w in key_words:\n",
    "    similar_words.append(key_w)\n",
    "    \n",
    "    for s_w, _ in model.wv.most_similar(key_w):\n",
    "        similar_words.append(s_w)\n",
    "        \n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learning', 'deep', 'scene', 'bioinformatics', 'mining', 'cmm', '或開', 'intellengent', 'minimal']\n",
      "Length = 55\n",
      "feature size = 150\n",
      "feature max: 1.5080113410949707, min: -1.600242018699646\n"
     ]
    }
   ],
   "source": [
    "total_words = similar_words\n",
    "features = model.wv.__getitem__(total_words)\n",
    "\n",
    "print(total_words[:10])\n",
    "print('Length = {}\\nfeature size = {}'.format(features.shape[0], features.shape[1]))\n",
    "print('feature max: {}, min: {}'.format(features.max(), features.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "tsne = TSNE(perplexity=20, n_components=2, random_state=SEED)\n",
    "X_tsne = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/bokeh/models/plots.py:725: UserWarning: \n",
      "You are attemptings to set `plot.legend.location` on a plot that has zero legends added, this will have no effect.\n",
      "\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with the 'legend' parameter set.\n",
      "\n",
      "  warnings.warn(_LEGEND_EMPTY_WARNING % attr)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"ce24821e-0610-47f8-a573-5f2295778e51\" data-root-id=\"1008\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"905aa7fe-fc16-4e0b-b6f3-447b501e94e9\":{\"roots\":{\"references\":[{\"attributes\":{\"min_border\":1,\"plot_width\":1000,\"renderers\":[{\"id\":\"1026\",\"type\":\"BoxAnnotation\"},{\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"id\":\"1005\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"1007\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1024\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1010\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1014\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1012\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1016\",\"type\":\"LinearScale\"}},\"id\":\"1008\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"plot\":null,\"text\":\"T-SNE visualization of Trump's twitts\"},\"id\":\"1007\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"1010\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"1012\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1004\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1034\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1035\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1037\",\"type\":\"CDSView\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1026\",\"type\":\"BoxAnnotation\"}},\"id\":\"1020\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"content\",\"@content\"]]},\"id\":\"1022\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"SaveTool\"},{\"attributes\":{\"level\":\"glyph\",\"plot\":{\"id\":\"1008\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"1004\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"label\"},\"text_font_size\":{\"value\":\"6pt\"},\"x\":{\"field\":\"x\"},\"x_offset\":{\"value\":5},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":5}},\"id\":\"1005\",\"type\":\"LabelSet\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"red\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\",\"skyblue\"],\"content\":[\"machine\",\"learning\",\"deep\",\"scene\",\"bioinformatics\",\"mining\",\"cmm\",\"\\u6216\\u958b\",\"intellengent\",\"minimal\",\"vision\",\"learning\",\"machine\",\"deep\",\"onnx\",\"supervised\",\"reinforcement\",\"original\",\"unsupervised\",\"dnn\",\"tx\",\"\\u2014\",\"cnn\",\"rnn\",\"lstm\",\"rcnn\",\"resnet\",\"bnn\",\"\\u5be6\\u4f5c\\u7df4\\u7fd2\",\"gan\",\"twn\",\"vggnet\",\"yolo\",\"svm\",\"knn\",\"random\",\"forest\",\"multivariable\",\"calculus\",\"boosting\",\"\\u56de\\u6b78\",\"natworks\",\"sklearn\",\"\\u805a\\u985e\",\"\\u6df1\\u5ea6\",\"recursive\",\"\\u8a08\\u5b78\\u7fd2\",\"\\u5982\\u7d71\",\"\\u63a8\\u7406\",\"\\u8c9d\\u8449\\u65af\",\"\\u795e\\u7d93\",\"\\u5e38\\u7528\",\"bnn\",\"\\u71b1\\u8aa0\\u8207\",\"\\u4e26\\u61c9\\u7528\"],\"label\":[\"machine\",\"learning\",\"deep\",\"scene\",\"bioinformatics\",\"mining\",\"cmm\",\"\\u6216\\u958b\",\"intellengent\",\"minimal\",\"vision\",\"learning\",\"machine\",\"deep\",\"onnx\",\"supervised\",\"reinforcement\",\"original\",\"unsupervised\",\"dnn\",\"tx\",\"\\u2014\",\"cnn\",\"rnn\",\"lstm\",\"rcnn\",\"resnet\",\"bnn\",\"\\u5be6\\u4f5c\\u7df4\\u7fd2\",\"gan\",\"twn\",\"vggnet\",\"yolo\",\"svm\",\"knn\",\"random\",\"forest\",\"multivariable\",\"calculus\",\"boosting\",\"\\u56de\\u6b78\",\"natworks\",\"sklearn\",\"\\u805a\\u985e\",\"\\u6df1\\u5ea6\",\"recursive\",\"\\u8a08\\u5b78\\u7fd2\",\"\\u5982\\u7d71\",\"\\u63a8\\u7406\",\"\\u8c9d\\u8449\\u65af\",\"\\u795e\\u7d93\",\"\\u5e38\\u7528\",\"bnn\",\"\\u71b1\\u8aa0\\u8207\",\"\\u4e26\\u61c9\\u7528\"],\"x\":{\"__ndarray__\":\"Zzs9wugdAMIhtVu+fMbuwRuZMcJ83GbCo4V2wvaqLMKEQCvCFaFpwu89kMKjJgPCl+tKwmA8v8Dhor5BTqznQY19PEDiMPlBYabRQXy/LELzwqjBn/ExwSNegkJLHJhCpyyfQib8AkF0mLpB+VNVwicMK0KbO4VCNheDwvpTdUE1gY3AUp5UP8zQCD+EA6LBEC7CwcH4lMAqiMJAOhgRQjevyUEOFVNBiS8IQphOC0KvbSFCq/HlQaSmnEGnMAlBoY80Qb1VekFZZMrBzCdJwSOVYsIcUU7AVnDAwQ==\",\"dtype\":\"float32\",\"shape\":[55]},\"y\":{\"__ndarray__\":\"HSkSwnRH/cGHLUHCAnpxwjxxa8JdBfTApzGRwi9m0kCJlJDCcNxKwsRy/8GcxKfBCfLSwTMPZMLCdQ7CWNOPwhUjmMLXtdzB1fqkwvDJM8Jsci3CG+zfwRop9UAfyvpApnu6QR34L8GR0C/B4dNZQreUKMGEQ3DBnYNNQv95qsELMw6/LlHKQm4Mo0ItCMtCANG4QtkAhULNp4BCuRqoQsZCZkKl0ZpC6SooQnZgf0JaEr9BApo6QWU450FdsfhBw8CEQWlnLULsuitCyuPAQZhAKkKXHCNC+9W8QQ==\",\"dtype\":\"float32\",\"shape\":[55]}},\"selected\":{\"id\":\"1040\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1041\",\"type\":\"UnionRenderers\"}},\"id\":\"1004\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1018\",\"type\":\"PanTool\"},{\"id\":\"1019\",\"type\":\"WheelZoomTool\"},{\"id\":\"1020\",\"type\":\"BoxZoomTool\"},{\"id\":\"1021\",\"type\":\"ResetTool\"},{\"id\":\"1022\",\"type\":\"HoverTool\"},{\"id\":\"1023\",\"type\":\"SaveTool\"}]},\"id\":\"1024\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1004\",\"type\":\"ColumnDataSource\"}},\"id\":\"1037\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.8},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.8},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1026\",\"type\":\"BoxAnnotation\"}],\"root_ids\":[\"1008\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
       "  var render_items = [{\"docid\":\"905aa7fe-fc16-4e0b-b6f3-447b501e94e9\",\"roots\":{\"1008\":\"ce24821e-0610-47f8-a573-5f2295778e51\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1008"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_tsne = X_tsne[:, 0]\n",
    "y_tsne = X_tsne[:, 1]\n",
    "label = total_words\n",
    "contents = total_words\n",
    "\n",
    "\n",
    "cluster_colors = {0: 'blue', 1: 'green', 2: 'yellow', 3: 'red', 4: 'skyblue', 5:'salmon', 6:'orange', 7:'maroon', 8:'crimson', 9:'black', 10:'gray'}\n",
    "\n",
    "# labels = ['Topic {}'.format(i) for i in topic_tfidf]\n",
    "topic_colors = [cluster_colors[index//11] for index, _ in enumerate(total_words)]\n",
    "\n",
    "settings = dict(x=x_tsne,\n",
    "               y=y_tsne,\n",
    "                label=label,\n",
    "                color=topic_colors,\n",
    "               content=contents\n",
    "               )\n",
    "\n",
    "source = ColumnDataSource(settings)\n",
    "\n",
    "labels = LabelSet(x='x', y='y', text='label', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas', text_font_size='6pt')\n",
    "\n",
    "\n",
    "title = 'T-SNE visualization of Trump\\'s twitts'\n",
    "\n",
    "plot_lda = figure(plot_width=1000, plot_height=600,\n",
    "                     title=title, tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.scatter(x='x', y='y',\n",
    "#                  legend='label', \n",
    "                 source=source, \n",
    "                 color='color',\n",
    "                 alpha=0.8, size=10)#'msize', )\n",
    "\n",
    "\n",
    "plot_lda.add_layout(labels)\n",
    "\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content\"}\n",
    "plot_lda.legend.location = \"top_left\"\n",
    "\n",
    "show(plot_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
